# H·ªá Th·ªëng L∆∞u Tr·ªØ Log Chu·∫©n H√≥a - Chi Ti·∫øt ƒê·∫ßy ƒê·ªß

H·ªá th·ªëng c√≥ **2 LU·ªíNG L∆ØU TR·ªÆ SONG SONG**:

## üîÑ T·ªïng Quan 2 Lu·ªìng L∆∞u Tr·ªØ

```mermaid
graph TB
    A[Log Synthesis<br/>T·∫°o Raw Logs] --> B[Ingestion Interface<br/>Port 8004]
    
    B --> C[Lu·ªìng 1: Raw Logs<br/>L∆∞u File System]
    B --> D[Lu·ªìng 2: Forward to<br/>Log Consolidation]
    
    C --> E[/app/logs/<br/>13 categories + anomaly/]
    
    D --> F[Log Consolidation<br/>Port 8005]
    F --> G[Chu·∫©n h√≥a OpenTelemetry]
    G --> H[File Storage<br/>M·∫∑c ƒë·ªãnh: B·∫≠t]
    G --> I[RAM Storage<br/>M·∫∑c ƒë·ªãnh: T·∫Øt]
    
    style C fill:#ffd43b
    style D fill:#51cf66
    style G fill:#ff6b6b
    style H fill:#4CAF50
    style I fill:#FF9800
```

## üìÅ LU·ªíNG 1: Raw Logs (File System)

### V·ªã Tr√≠ v√† Format

```bash
00-mock-servers/logs/
‚îú‚îÄ‚îÄ infrastructure/
‚îÇ   ‚îî‚îÄ‚îÄ server_log_20250103.log         # Raw JSON lines
‚îú‚îÄ‚îÄ application/
‚îÇ   ‚îî‚îÄ‚îÄ application_log_20250103.log    # Raw JSON lines
‚îú‚îÄ‚îÄ security/
‚îÇ   ‚îî‚îÄ‚îÄ authentication_log_20250103.log # Raw JSON lines
‚îî‚îÄ‚îÄ anomaly/
    ‚îî‚îÄ‚îÄ fraud_detection_log_20250103.log # Anomaly score > 70
```

### V√≠ D·ª• Raw Log
```json
{
  "timestamp": "2025-01-03T10:30:45.123456Z",
  "log_type": "payment_transaction_log",
  "data": {
    "transaction_id": "TXN20250103",
    "amount": 5000000,
    "anomaly_score": 85.5
  }
}
```

## üéØ LU·ªíNG 2: Chu·∫©n H√≥a OpenTelemetry (Log Consolidation)

### N∆°i L∆∞u Tr·ªØ Logs Chu·∫©n H√≥a

#### 1. **File Storage** (M·∫∑c ƒë·ªãnh: B·∫≠t) ‚úÖ
```bash
/app/logs/consolidated/
‚îî‚îÄ‚îÄ consolidated_logs_20251103.jsonl    # M·ªôt file m·ªói ng√†y
```

#### 2. **RAM Storage** (M·∫∑c ƒë·ªãnh: T·∫Øt - Ti·∫øt ki·ªám 2GB RAM) ‚ö†Ô∏è
```python
# B·∫≠t ch·ªâ khi c·∫ßn real-time analytics
ENABLE_RAM_STORAGE="true"           # Default: false
MAX_RAM_LOGS="1000"                 # Gi·∫£m t·ª´ 10,000 ƒë·ªÉ ti·∫øt ki·ªám RAM

# log-consolidation/app.py
consolidated_logs: List[LogRecordObject] = []
logs_by_source: Dict[str, List[LogRecordObject]] = {}
```

### Environment Variables Configuration

```yaml
# docker-compose.yml
services:
  log-consolidation:
    environment:
      - ENABLE_RAM_STORAGE=false    # üîÑ M·∫∑c ƒë·ªãnh: T·∫ÆT (ti·∫øt ki·ªám RAM)
      - ENABLE_FILE_STORAGE=true   # üîÑ M·∫∑c ƒë·ªãnh: B·∫¨T (l∆∞u file)
      - MAX_RAM_LOGS=1000          # Gi·∫£m Memory footprint
    volumes:
      - ./logs:/app/logs           # Mount th∆∞ m·ª•c logs
```

#### 2. **C·∫•u Tr√∫c OpenTelemetry LogRecord**
```python
class LogRecordObject:
    timestamp: str                    # "2025-01-03T10:30:45.123456789Z"
    body: Union[str, dict, list]     # N·ªôi dung ch√≠nh
    observed_timestamp: str           # Th·ªùi ƒëi·ªÉm nh·∫≠n log
    severity_text: Severity           # INFO, WARN, ERROR, FATAL
    severity_number: SeverityNumber   # 1-24 scale
    trace_id: Optional[str]          # Correlation v·ªõi traces
    span_id: Optional[str]           # Correlation v·ªõi spans
    attributes: Dict[str, Any]       # Metadata phong ph√∫
    resource: Resource               # Service/host info
    instrumentation_scope: InstrumentationScope
```

### V√≠ D·ª• Log ƒê√£ Chu·∫©n H√≥a

```json
{
  "timestamp": "2025-01-03T10:30:45.123456789Z",
  "body": "Transaction TXN20250103: failed - 5,000,000 VND",
  "observed_timestamp": "2025-01-03T10:30:45.500000Z",
  "severity_text": "ERROR",
  "severity_number": 17,
  "trace_id": "4bf92f3577b34da6a3ce929d0e0e4736",
  "span_id": "00f067aa0ba902b7",
  "attributes": {
    "source": "log-synthesis",
    "original_log_type": "payment_transaction_log",
    "log.category": "transaction",
    "transaction_id": "TXN20250103",
    "amount": 5000000,
    "currency": "VND",
    "anomaly_score": 85.5,
    "anomaly.high": true,
    "performance.processing_time_ms": 2500,
    "user_id": "USR123456",
    "ip_address": "113.161.1.1"
  },
  "resource": {
    "attributes": {
      "service.name": "log-synthesis-service",
      "service.version": "1.0.0",
      "host.name": "payment-server-01",
      "host.ip": "113.161.1.1",
      "environment": "development",
      "deployment.environment": "docker",
      "log.category": "transaction"
    }
  },
  "instrumentation_scope": {
    "name": "log-synthesis.payment_transaction",
    "version": "1.0.0"
  }
}
```

## üìä Truy C·∫≠p Logs Chu·∫©n H√≥a

### 1. **Qua API Endpoints**

```python
# L·∫•y logs chu·∫©n h√≥a g·∫ßn nh·∫•t
GET http://localhost:8005/api/consolidated-logs

Response:
{
  "logs": [
    {
      "timestamp": "2025-01-03T10:30:45.123456789Z",
      "body": "Security event: authentication_failure from user USR123456",
      "severity_text": "ERROR",
      "severity_number": 17,
      "attributes": {...},
      "resource": {...}
    }
  ],
  "total_count": 8542,
  "sources": ["log-synthesis", "scenario-orchestrator", "pattern-generator"]
}
```

### 2. **L·ªçc Theo Source**
```python
GET http://localhost:8005/api/consolidated-logs/by-source/log-synthesis
```

### 3. **Aggregation Statistics**
```python
GET http://localhost:8005/api/aggregation/stats

Response:
{
  "summary": {
    "total_logs": 10000,
    "unique_sources": 5,
    "high_anomaly_logs": 342,
    "severity_weight_score": 45230
  },
  "severity_distribution": {
    "INFO": 6500,
    "WARN": 2000,
    "ERROR": 1300,
    "FATAL": 200
  },
  "anomaly_analysis": {
    "avg_anomaly_score": 35.7,
    "max_anomaly_score": 98.5,
    "high_anomaly_percentage": 3.42
  }
}
```

### 4. **Timeline Analysis**
```python
GET http://localhost:8005/api/aggregation/timeline?minutes=60

Response:
{
  "timeline": [
    {
      "timestamp": "2025-01-03T10:00:00Z",
      "count": 150,
      "severity_counts": {"INFO": 100, "WARN": 30, "ERROR": 20},
      "avg_anomaly_score": 25.5,
      "high_anomaly_count": 5
    }
  ]
}
```

## üîç So S√°nh 2 Lo·∫°i Log

| ƒê·∫∑c ƒëi·ªÉm | Raw Logs (File) | Chu·∫©n H√≥a (OpenTelemetry) |
|----------|-----------------|---------------------------|
| **V·ªã tr√≠ l∆∞u** | `/app/logs/category/` | `/app/logs/consolidated/` (File) |
| **Storage Type** | File system | **File (m·∫∑c ƒë·ªãnh) + RAM (t√πy ch·ªçn)** |
| **Format** | JSON lines ƒë∆°n gi·∫£n | OpenTelemetry LogRecord ƒë·∫ßy ƒë·ªß |
| **Persistence** | Vƒ©nh vi·ªÖn (disk) | **Vƒ©nh vi·ªÖn (file) + T·∫°m th·ªùi (RAM)** |
| **Memory footprint** | Th·∫•p | **Th·∫•p (ch·ªâ file) ho·∫∑c Cao (n·∫øu b·∫≠t RAM)** |
| **C·∫•u tr√∫c** | Simple, flat | Rich, nested v·ªõi metadata |
| **Severity** | Kh√¥ng c√≥ | T·ª± ƒë·ªông x√°c ƒë·ªãnh |
| **Trace context** | Kh√¥ng c√≥ | trace_id, span_id |
| **Query** | grep, awk, jq | REST API ho·∫∑c file parsing |
| **Use case** | Long-term storage, audit | **Long-term (file) + Real-time (RAM)** |
| **T·ªëi ∆∞u cho 2GB RAM** | ‚úÖ | **‚úÖ (File storage mode)** |

## üíæ Export Logs Chu·∫©n H√≥a Ra File

### Web UI Export
```javascript
// T·ª´ giao di·ªán web http://localhost:8005
function exportLogs() {
    const dataStr = JSON.stringify(filteredLogs, null, 2);
    const dataBlob = new Blob([dataStr], {type: 'application/json'});
    const url = URL.createObjectURL(dataBlob);
    const link = document.createElement('a');
    link.href = url;
    link.download = `consolidated_logs_${new Date().toISOString()}.json`;
    link.click();
}
```

### Command Line Export

**Read from API (File or RAM Storage)**:
```bash
# Export t·∫•t c·∫£ logs chu·∫©n h√≥a
curl http://localhost:8005/api/consolidated-logs > consolidated_logs.json

# Export v·ªõi pretty print  
curl http://localhost:8005/api/consolidated-logs | jq '.' > formatted_logs.json

# Export ch·ªâ high anomaly logs
curl http://localhost:8005/api/consolidated-logs | \
  jq '.logs[] | select(.attributes.anomaly_score > 70)' > anomaly_logs.json
```

**Direct File Access (File Storage Mode)**:
```bash
# ƒê·ªçc tr·ª±c ti·∫øp t·ª´ file JSONL
cat /app/logs/consolidated/consolidated_logs_20251103.jsonl

# Filter high anomaly scores t·ª´ file
cat /app/logs/consolidated/consolidated_logs_20251103.jsonl | \
  jq 'select(.attributes.anomaly_score > 70)'

# ƒê·∫øm s·ªë logs theo severity
cat /app/logs/consolidated/consolidated_logs_20251103.jsonl | \
  jq -r '.severity_text' | sort | uniq -c
```

## üöÄ T√≠ch H·ª£p v·ªõi External Systems

### G·ª≠i Logs Chu·∫©n H√≥a ƒë·∫øn Elasticsearch

```python
# V√≠ d·ª• integration (ch∆∞a implement)
async def forward_to_elasticsearch(logs: List[LogRecordObject]):
    for log in logs:
        doc = {
            "@timestamp": log.timestamp,
            "message": log.body,
            "severity": log.severity_text,
            "trace.id": log.trace_id,
            "span.id": log.span_id,
            **log.attributes
        }
        await es_client.index(
            index=f"logs-{datetime.now():%Y.%m.%d}",
            body=doc
        )
```

## üìà Monitoring Dashboard

### Truy c·∫≠p Web UI
```
http://localhost:8005/
```

### T√≠nh nƒÉng Web UI:
- **Real-time stats**: T·ªïng logs, sources, severity distribution
- **Filtering**: L·ªçc theo source, severity, search text
- **Visual logs**: Hi·ªÉn th·ªã logs v·ªõi color-coded severity
- **Export**: Download JSON tr·ª±c ti·∫øp t·ª´ browser
- **Simulation**: Test ingestion v·ªõi sample data

## üéØ T√≥m T·∫Øt

**H·ªá th·ªëng l∆∞u tr·ªØ 2 lo·∫°i log song song:**

1. **Raw Logs** (Ingestion Interface):
   - L∆∞u vƒ©nh vi·ªÖn tr√™n disk
   - Format JSON lines ƒë∆°n gi·∫£n
   - Ph√¢n lo·∫°i theo 13 categories + anomaly
   - Ph·ª•c v·ª• long-term storage v√† audit

2. **Chu·∫©n H√≥a OpenTelemetry** (Log Consolidation) - **üîÑ C·∫¢I TI·∫æN CHO 2GB RAM**:
   - **File Storage (M·∫∑c ƒë·ªãnh: B·∫≠t)**: L∆∞u vƒ©nh vi·ªÖn v√†o `/app/logs/consolidated/YYYYMMDD.jsonl`
   - **RAM Storage (M·∫∑c ƒë·ªãnh: T·∫Øt)**: Optional cho real-time analysis
   - Format OpenTelemetry LogRecord ƒë·∫ßy ƒë·ªß
   - T·ª± ƒë·ªông x√°c ƒë·ªãnh severity v√† trace context
   - **T·ªëi ∆∞u cho h·ªá th·ªëng 2GB RAM**

**L√Ω-do m·ªõi c·∫ßn c·∫£ 2:**
- Raw logs: Backup, compliance, forensics
- Chu·∫©n h√≥a file storage: Long-term v·ªõi format chu·∫©n, **ti·∫øt ki·ªám RAM**
- Chu·∫©n h√≥a RAM storage: Real-time analysis (t√πy ch·ªçn khi c·∫ßn)

**Configuration cho m√¥i tr∆∞·ªùng 2GB RAM:**
```yaml
# T·ªëi ∆∞u memory footprint
ENABLE_RAM_STORAGE=false    # ‚ö†Ô∏è T·∫ÆT ƒë·ªÉ ti·∫øt ki·ªám RAM
ENABLE_FILE_STORAGE=true    # ‚úÖ B·∫¨T ƒë·ªÉ l∆∞u file
MAX_RAM_LOGS=1000          # Gi·∫£m limits n·∫øu c·∫ßn b·∫≠t RAM
```