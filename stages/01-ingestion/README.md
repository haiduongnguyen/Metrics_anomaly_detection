# Stage 01 - Ingestion Layer

## 1. Giá»›i Thiá»‡u

Stage 01 - Ingestion Layer lÃ  lá»›p tiáº¿p nháº­n vÃ  streaming dá»¯ liá»‡u, káº¿t ná»‘i giá»¯a Stage 00 (Mock Servers) vÃ  cÃ¡c stage xá»­ lÃ½ phÃ­a sau. Lá»›p nÃ y sá»­ dá»¥ng **Amazon Kinesis Data Streams** Ä‘á»ƒ streaming real-time vÃ  **Amazon S3** Ä‘á»ƒ lÆ°u trá»¯ raw data theo cáº¥u trÃºc partition chuáº©n, sáºµn sÃ ng cho cÃ¡c cÃ´ng viá»‡c ETL vÃ  phÃ¢n tÃ­ch á»Ÿ cÃ¡c stage tiáº¿p theo.

### Ná»‘i Tiáº¿p Tá»« Stage 00

á» Stage 00, chÃºng ta Ä‘Ã£ cÃ³ há»‡ thá»‘ng Mock Servers vá»›i 6 microservices táº¡o ra 59 loáº¡i log Ä‘a dáº¡ng, Ä‘Æ°á»£c chuáº©n hÃ³a theo OpenTelemetry format vÃ  lÆ°u vÃ o file system local. Stage 01 tiáº¿p ná»‘i báº±ng cÃ¡ch:

1. **Nháº­n logs tá»« Stage 00** qua Ingestion Interface (port 8004)
2. **Stream vÃ o Kinesis** Ä‘á»ƒ xá»­ lÃ½ real-time
3. **LÆ°u vÃ o S3** vá»›i partition structure chuáº©n AWS
4. **Cung cáº¥p dashboard** Ä‘á»ƒ monitor vÃ  quáº£n lÃ½

Äiá»u nÃ y cho phÃ©p logs khÃ´ng chá»‰ Ä‘Æ°á»£c lÆ°u local mÃ  cÃ²n Ä‘i vÃ o má»™t data pipeline AWS-compatible, sáºµn sÃ ng cho big data processing.

## 2. Kiáº¿n TrÃºc Há»‡ Thá»‘ng

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Stage 00 - Mock Servers                             â”‚
â”‚  â”œâ”€ Scenario Orchestrator (8000)                     â”‚
â”‚  â”œâ”€ Pattern Generator (8001)                         â”‚
â”‚  â”œâ”€ Log Synthesis (8002) - 59 log types             â”‚
â”‚  â”œâ”€ State Manager (8003)                             â”‚
â”‚  â”œâ”€ Ingestion Interface (8004) â—„â”€â”€ Receives logs    â”‚
â”‚  â””â”€ Log Consolidation (8005)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â”‚ Kinesis PutRecords (boto3)
                     â”‚ Partition Key: service name
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LocalStack (Port 4566)                              â”‚
â”‚  â”œâ”€ Kinesis Data Streams                             â”‚
â”‚  â”‚  â”œâ”€ stage01-logs-stream (ACTIVE, 1 shard)        â”‚
â”‚  â”‚  â””â”€ stage01-metrics-stream (ACTIVE, 1 shard)     â”‚
â”‚  â”‚                                                    â”‚
â”‚  â””â”€ S3 Raw Buckets                                   â”‚
â”‚     â”œâ”€ md-raw-logs (partitioned storage)            â”‚
â”‚     â”œâ”€ md-raw-metrics                                â”‚
â”‚     â””â”€ md-raw-apm                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â”‚ GetRecords (polling every 5s)
                     â”‚ Batch size: 100 records
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Kinesis Consumer Service                            â”‚
â”‚  â”œâ”€ Reads from Kinesis stream                        â”‚
â”‚  â”œâ”€ Parses JSON logs                                 â”‚
â”‚  â”œâ”€ Groups by partition (service + time)             â”‚
â”‚  â””â”€ Writes to S3 (JSONL format)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  S3 Partitioned Storage                              â”‚
â”‚  service=<svc>/year=YYYY/month=MM/day=DD/hour=HH/    â”‚
â”‚    part-<uuid>.jsonl                                 â”‚
â”‚                                                       â”‚
â”‚  Example:                                            â”‚
â”‚  service=api-gateway/                                â”‚
â”‚    year=2025/month=11/day=09/hour=13/                â”‚
â”‚      part-abc123.jsonl                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Monitoring Dashboard

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Stage 01 Dashboard (Port 8010)                      â”‚
â”‚  â”œâ”€ Real-time Kinesis monitoring                     â”‚
â”‚  â”œâ”€ S3 bucket browser                                â”‚
â”‚  â”œâ”€ Partition analysis                               â”‚
â”‚  â””â”€ Integrated log viewer                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## 3. CÃ¡c ThÃ nh Pháº§n ChÃ­nh

### 3.1. LocalStack - AWS Services Emulator
- **Port**: 4566
- **Services**: S3, Kinesis, Lambda, IAM, CloudWatch
- **Purpose**: MÃ´ phá»ng AWS services cho local development
- **Configuration**: 
  - PERSISTENCE=0 (no data persistence Ä‘á»ƒ trÃ¡nh conflicts)
  - LAMBDA_EXECUTOR=local (simplified execution)
  - Tá»± Ä‘á»™ng khá»Ÿi táº¡o resources qua init scripts

### 3.2. Kinesis Data Streams
- **stage01-logs-stream**: Stream chÃ­nh cho logs
  - Retention: 24 hours
  - Shards: 1 (cÃ³ thá»ƒ scale)
  - Throughput: 1MB/s write, 2MB/s read
  
- **stage01-metrics-stream**: Stream cho metrics (future use)
  - Same configuration as logs stream

### 3.3. S3 Raw Buckets
- **md-raw-logs**: LÆ°u trá»¯ raw logs vá»›i partition structure
- **md-raw-metrics**: LÆ°u trá»¯ raw metrics
- **md-raw-apm**: LÆ°u trá»¯ APM metrics

**Partition Structure** (tÆ°Æ¡ng thÃ­ch Athena/Glue):
```
service=<service_name>/
  year=YYYY/
    month=MM/
      day=DD/
        hour=HH/
          part-<uuid>.jsonl
```

### 3.4. Kinesis Consumer Service
- **Language**: Python 3.11
- **Function**: Continuously polls Kinesis vÃ  writes to S3
- **Configuration**:
  - Poll interval: 5 seconds
  - Batch size: 100 records
  - Auto-restart on errors
  
**Why Consumer Service instead of Lambda?**
LocalStack Community Edition has limitations vá»›i Lambda (functions stay in Pending state). Consumer service lÃ  giáº£i phÃ¡p thay tháº¿ hoáº¡t Ä‘á»™ng tá»‘t vÃ  sáºµn sÃ ng migrate lÃªn Lambda khi deploy AWS tháº­t.

### 3.5. Stage 01 Dashboard (Port 8010)
- **Web UI**: Modern, responsive interface
- **Features**:
  - Real-time Kinesis stream monitoring
  - S3 bucket browser vá»›i filtering
  - Partition structure analysis
  - Integrated log viewer (dark theme)
  - REST API endpoints
- **Auto-refresh**: Every 10 seconds
- **Technology**: FastAPI + boto3 + vanilla JavaScript

## 4. TÃ­ch Há»£p vá»›i Stage 00

### 4.1. Kinesis Producer Integration

Stage 00 Ingestion Interface (port 8004) Ä‘Ã£ Ä‘Æ°á»£c tÃ­ch há»£p Kinesis producer:

```python
# File: 00-mock-servers/05-ingestion-interface/kinesis_producer.py
class KinesisProducer:
    - Káº¿t ná»‘i Ä‘áº¿n LocalStack Kinesis
    - Batch logs vÃ  gá»­i qua PutRecords API
    - Partition key: service name
    - Auto-retry on failures
```

**Environment Variables**:
```yaml
KINESIS_ENABLED: true
AWS_ENDPOINT_URL: http://localstack:4566
AWS_DEFAULT_REGION: us-east-1
KINESIS_STREAM_NAME: stage01-logs-stream
```

### 4.2. Data Flow

```
Stage 00: Log Synthesis
    â†“ (POST /api/ingest/batch)
Stage 00: Ingestion Interface
    â”œâ”€â†’ Local file storage (logs/<category>/)
    â”œâ”€â†’ Forward to Consolidation (8005)
    â””â”€â†’ Send to Kinesis (boto3 PutRecords) âœ¨ NEW
    
Kinesis Stream
    â†“ (GetRecords polling)
    
Kinesis Consumer
    â”œâ”€â†’ Parse JSON logs
    â”œâ”€â†’ Group by partition
    â””â”€â†’ Write to S3 (partitioned JSONL)
    
S3 Raw Buckets
    â””â”€â†’ Ready for Stage 02 (ETL)
```

## 5. CÃ i Äáº·t vÃ  Cháº¡y

### 5.1. YÃªu Cáº§u Há»‡ Thá»‘ng
- Docker & Docker Compose v2.0+
- Minimum 2GB RAM
- 10GB disk space
- Stage 00 Ä‘Ã£ Ä‘Æ°á»£c setup (xem `stages/00-mock-servers/README.md`)

### 5.2. Khá»Ÿi Äá»™ng (Standalone Mode)

Náº¿u chá»‰ muá»‘n cháº¡y Stage 01:

```bash
cd stages/01-ingestion
./start.sh
```

Script nÃ y sáº½:
1. Detect LocalStack Ä‘ang cháº¡y hoáº·c start má»›i
2. Connect vÃ o `anomaly-network`
3. Initialize Kinesis streams vÃ  S3 buckets
4. Start dashboard service

### 5.3. Khá»Ÿi Äá»™ng (Full Pipeline Mode)

**Khuyáº¿n nghá»‹**: Cháº¡y toÃ n bá»™ pipeline tá»« thÆ° má»¥c stages/:

```bash
cd stages
docker compose up -d
```

Hoáº·c:

```bash
./start.sh
```

## 6. Sá»­ Dá»¥ng

### 6.1. Access Dashboard

**URL**: http://localhost:8010

Dashboard cung cáº¥p:
- ğŸ“Š Real-time statistics (Kinesis + S3)
- ğŸ“¡ Kinesis stream status monitoring
- ğŸ—„ï¸ S3 bucket browser
- ğŸ“ Partition structure analysis
- ğŸ“„ Integrated log viewer

### 6.2. Monitor Data Flow

**Terminal 1 - Ingestion Interface** (Producer):
```bash
docker compose logs -f ingestion-interface | grep Kinesis
```

Expect:
```
âœ… [Kinesis Producer] Sent 100 logs to stage01-logs-stream
```

**Terminal 2 - Kinesis Consumer**:
```bash
docker compose logs -f kinesis-consumer
```

Expect:
```
âœ… Wrote 100 logs to s3://md-raw-logs/service=api-gateway/...
ğŸ“Š Batch processed: 100 records, 100 written, 0 failed
ğŸ“ˆ Total processed: 300
```

### 6.3. Browse S3 Data

**Via Dashboard** (Recommended):
```
1. Open http://localhost:8010
2. Select bucket: md-raw-logs
3. Click "Refresh"
4. Click "View" on any object
```

**Via CLI**:
```bash
# List all objects
awslocal s3 ls s3://md-raw-logs/ --recursive --endpoint-url http://localhost:4566

# Download sample
awslocal s3 cp s3://md-raw-logs/<key> sample.jsonl --endpoint-url http://localhost:4566

# View content
cat sample.jsonl | jq '.'
```

### 6.4. Test Pipeline

**Automated Test**:
```bash
cd stages
./test-pipeline.sh
```

**Manual Test**:
```bash
# 1. Trigger log generation tá»« Stage 00
curl -X POST http://localhost:8000/api/continuous/start \
  -H "Content-Type: application/json" \
  -d '{
    "interval_seconds": 2,
    "logs_per_interval": 10,
    "duration_seconds": 60
  }'

# 2. Monitor qua Dashboard: http://localhost:8010

# 3. Check S3 data
awslocal s3 ls s3://md-raw-logs/ --recursive --endpoint-url http://localhost:4566

# 4. Stop generation
curl -X POST http://localhost:8000/api/continuous/stop
```

## 7. API Endpoints

### Dashboard APIs

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/health` | GET | Health check |
| `/api/stats/summary` | GET | Overall statistics |
| `/api/kinesis/streams` | GET | List Kinesis streams |
| `/api/kinesis/stream/{name}/metrics` | GET | Stream details |
| `/api/s3/buckets` | GET | List S3 buckets |
| `/api/s3/bucket/{name}/objects` | GET | List objects in bucket |
| `/api/s3/bucket/{name}/partitions` | GET | Partition analysis |
| `/api/s3/object/{bucket}/{key}` | GET | View log content |

**Example**:
```bash
# Get summary
curl http://localhost:8010/api/stats/summary | jq

# List streams
curl http://localhost:8010/api/kinesis/streams | jq

# Browse S3
curl http://localhost:8010/api/s3/bucket/md-raw-logs/objects | jq
```

## 8. Cáº¥u TrÃºc ThÆ° Má»¥c

```
01-ingestion/
â”œâ”€â”€ dashboard/                    # Web UI service
â”‚   â”œâ”€â”€ app.py                   # FastAPI application
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ kinesis-consumer/            # Consumer service
â”‚   â”œâ”€â”€ consumer.py              # Kinesis polling & S3 writing
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ Dockerfile
â”‚
â”œâ”€â”€ localstack-init/             # LocalStack initialization
â”‚   â””â”€â”€ 01-setup-resources.sh   # Auto-create streams & buckets
â”‚
â”œâ”€â”€ docker-compose.yml           # Lightweight config (uses existing LocalStack)
â”œâ”€â”€ docker-compose.standalone.yml # Standalone mode
â”œâ”€â”€ start.sh                     # Smart startup script
â”œâ”€â”€ stop.sh                      # Shutdown script
â”œâ”€â”€ test-kinesis.sh              # Test script
â”œâ”€â”€ plan.md                      # Architecture plan (reference)
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md                    # This file
```

## 9. Configuration

### Environment Variables

**Ingestion Interface (Stage 00)**:
```yaml
KINESIS_ENABLED: true                    # Enable Kinesis producer
AWS_ENDPOINT_URL: http://localstack:4566 # LocalStack endpoint
AWS_DEFAULT_REGION: us-east-1
KINESIS_STREAM_NAME: stage01-logs-stream
```

**Kinesis Consumer**:
```yaml
AWS_ENDPOINT_URL: http://localstack:4566
AWS_DEFAULT_REGION: us-east-1
STREAM_NAME: stage01-logs-stream
TARGET_BUCKET: md-raw-logs
POLL_INTERVAL: 5                         # Seconds between polls
BATCH_SIZE: 100                          # Records per batch
```

**Dashboard**:
```yaml
AWS_ENDPOINT_URL: http://localstack:4566
AWS_DEFAULT_REGION: us-east-1
```

### Resource Limits

**Optimized cho 2GB RAM systems**:
- LocalStack: No persistence, local executor
- Consumer: Minimal memory footprint (~50MB)
- Dashboard: ~50MB
- Total Stage 01: ~500-700MB RAM

## 10. Data Format

### Input (tá»« Stage 00)

```json
{
  "timestamp": "2025-11-09T13:24:33Z",
  "service": "api-gateway",
  "level": "INFO",
  "message": "Request processed successfully",
  "trace_id": "abc123xyz",
  "source": "log-synthesis",
  "log_type": "api_gateway_log",
  "anomaly_score": 5.2,
  "request_id": "req-456",
  "user_id": "user-789"
}
```

### Output (trong S3)

**File**: `s3://md-raw-logs/service=api-gateway/year=2025/month=11/day=09/hour=13/part-abc123.jsonl`

**Format**: JSONL (newline-delimited JSON), má»—i line lÃ  má»™t log entry giá»‘ng input

**Benefits**:
- TÆ°Æ¡ng thÃ­ch vá»›i AWS Glue Crawlers
- Athena-ready (cÃ³ thá»ƒ query ngay)
- Compressed-friendly (GZIP trong production)
- Partition pruning tá»‘i Æ°u query performance

## 11. Performance

### Throughput
- **Ingestion**: ~1000 logs/second (from Stage 00)
- **Kinesis**: 1MB/s per shard (~1000 records/s)
- **Consumer**: ~20 records/second (limited by poll interval)
- **S3 Write**: <1 second per batch

### Latency
- Stage 00 â†’ Kinesis: <1 second
- Kinesis â†’ Consumer: 5-10 seconds (poll interval)
- Consumer â†’ S3: <1 second
- **Total end-to-end**: 10-15 seconds

### Optimization Options
```yaml
# Faster consumption
POLL_INTERVAL: 2          # Reduce from 5s to 2s
BATCH_SIZE: 200           # Increase from 100 to 200

# Higher throughput
# Add more Kinesis shards (requires terraform)
# Deploy multiple consumer instances
```

## 12. Troubleshooting

### LocalStack khÃ´ng khá»Ÿi Ä‘á»™ng

```bash
# Check logs
docker logs localstack-anomaly

# Verify port not in use
lsof -i :4566

# Restart
docker compose restart localstack
```

### Kinesis Consumer khÃ´ng xá»­ lÃ½ records

```bash
# Check consumer logs
docker logs kinesis-consumer

# Verify stream exists
awslocal kinesis list-streams --endpoint-url http://localhost:4566

# Check stream status
awslocal kinesis describe-stream-summary --stream-name stage01-logs-stream --endpoint-url http://localhost:4566
```

### KhÃ´ng cÃ³ data trong S3

**BÆ°á»›c 1**: Verify Stage 00 Ä‘ang gá»­i logs
```bash
docker logs ingestion-interface | grep Kinesis
# Should show: "âœ… [Kinesis Producer] Sent X logs"
```

**BÆ°á»›c 2**: Check consumer Ä‘ang cháº¡y
```bash
docker logs kinesis-consumer | grep "Consuming from shard"
# Should show: "ğŸ“– Consuming from shard: shardId-000000000000"
```

**BÆ°á»›c 3**: Manual test
```bash
cd stages/01-ingestion
./test-kinesis.sh
```

**BÆ°á»›c 4**: Check S3 again
```bash
sleep 10
awslocal s3 ls s3://md-raw-logs/ --recursive --endpoint-url http://localhost:4566
```

### Dashboard khÃ´ng accessible

```bash
# Check container
docker ps | grep stage01-dashboard

# Check logs
docker logs stage01-dashboard

# Restart
docker compose restart stage01-dashboard

# Access
curl http://localhost:8010/health
```

## 13. Testing

### Quick Test

```bash
# From stages directory
cd /home/son/Documents/cursor-projects/Metrics_anomaly_detection/stages

# Run automated test
./test-pipeline.sh
```

Test nÃ y sáº½:
1. âœ… Verify all services healthy
2. âœ… Check LocalStack vÃ  Kinesis
3. âœ… Trigger test log generation
4. âœ… Wait for data flow
5. âœ… Verify S3 has data
6. âœ… Show sample logs

### Manual Verification

```bash
# 1. Check services
docker compose ps

# 2. Check Kinesis
awslocal kinesis describe-stream-summary --stream-name stage01-logs-stream --endpoint-url http://localhost:4566

# 3. Check S3
awslocal s3 ls s3://md-raw-logs/ --recursive --endpoint-url http://localhost:4566

# 4. View dashboard
open http://localhost:8010
```

## 14. Sá»± KhÃ¡c Biá»‡t vá»›i Stage 00

| Aspect | Stage 00 | Stage 01 |
|--------|----------|----------|
| **Purpose** | Generate mock logs | Stream & store logs |
| **Storage** | Local files only | Kinesis + S3 (AWS-compatible) |
| **Format** | Category-based folders | Time-partitioned S3 structure |
| **Processing** | OpenTelemetry consolidation | Real-time streaming pipeline |
| **Scalability** | Limited to single host | Horizontally scalable (shards) |
| **Query** | File-based grep/jq | Athena/Glue-ready |
| **Use Case** | Development, testing | Production data lake |

## 15. Migration to AWS

Stage 01 Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ dá»… dÃ ng migrate lÃªn AWS tháº­t:

### Changes Needed

**1. Environment Variables**:
```yaml
# Remove LocalStack endpoints
AWS_ENDPOINT_URL: ""  # Use default AWS

# Use real credentials (IAM roles)
# AWS_ACCESS_KEY_ID: <from IAM>
# AWS_SECRET_ACCESS_KEY: <from IAM>
```

**2. Switch to Lambda**:
- Lambda code Ä‘Ã£ cÃ³ sáºµn trong `lambda-consumer/` (backup)
- Deploy vá»›i AWS Lambda console hoáº·c Terraform
- Event source mapping tá»± Ä‘á»™ng setup

**3. Infrastructure as Code** (Future - BÆ°á»›c 2):
- Terraform modules trong `infra/` directory
- One command deploy: `terraform apply`
- Support for multiple environments (dev, staging, prod)

**4. KhÃ´ng cáº§n thay Ä‘á»•i**:
- âœ… Stage 00 services (cÃ³ thá»ƒ cháº¡y trÃªn ECS/EKS)
- âœ… S3 partition structure
- âœ… Kinesis partition key strategy
- âœ… Log format (JSONL)
- âœ… Dashboard code (chá»‰ Ä‘á»•i endpoint)

## 16. Next Steps

### Stage 01 - BÆ°á»›c 2 (Future Work)
- [ ] Terraform IaC structure (`infra/` directory)
- [ ] Terraform modules (s3_raw, kinesis, lambda, iam)
- [ ] Multiple environment support (localstack.tfvars, aws-dev.tfvars)
- [ ] State management (S3 backend)

### Stage 02 - ETL & Processing
- [ ] AWS Glue Crawlers scan S3 raw buckets
- [ ] Glue Data Catalog registration
- [ ] ETL Jobs: data cleaning, normalization, transformation
- [ ] Write to S3 transformed buckets

### Stage 03 - Hot & Cold Storage
- [ ] Redis/ElastiCache cho hot storage
- [ ] S3 lifecycle policies
- [ ] Athena query engine
- [ ] Data retention policies

## 17. Security & Best Practices

### Local Development
- âœ… Using test credentials (safe for local)
- âœ… Network isolation (Docker bridge)
- âœ… No external exposure (localhost only)

### Production Recommendations
- ğŸ”’ Enable S3 encryption (SSE-S3 or SSE-KMS)
- ğŸ”’ Use IAM roles instead of credentials
- ğŸ”’ Enable VPC endpoints
- ğŸ”’ CloudTrail audit logging
- ğŸ”’ KMS key management
- ğŸ”’ Bucket policies and access controls

## 18. Monitoring

### Health Checks

```bash
# All services
docker compose ps

# Individual checks
curl http://localhost:4566/_localstack/health      # LocalStack
curl http://localhost:8004/health                  # Ingestion Interface
curl http://localhost:8010/health                  # Dashboard
docker logs kinesis-consumer | grep "Consuming"    # Consumer
```

### Metrics

**Via Dashboard**: http://localhost:8010
- Kinesis stream status
- S3 object counts
- Data sizes
- Partition distribution

**Via CLI**:
```bash
# Kinesis metrics
awslocal kinesis describe-stream-summary --stream-name stage01-logs-stream --endpoint-url http://localhost:4566

# S3 metrics
awslocal s3 ls s3://md-raw-logs/ --recursive --endpoint-url http://localhost:4566 | wc -l
```

## 19. Performance Tuning

### For Higher Throughput

**Option 1**: Increase consumer speed
```yaml
# In docker-compose.yml
kinesis-consumer:
  environment:
    - POLL_INTERVAL=2    # From 5s to 2s
    - BATCH_SIZE=200     # From 100 to 200
```

**Option 2**: Multiple consumer instances
```yaml
# Add more consumers (requires different shard assignment)
kinesis-consumer-1:
  ...
kinesis-consumer-2:
  ...
```

**Option 3**: Increase Kinesis shards
```bash
# Via awslocal
awslocal kinesis update-shard-count --stream-name stage01-logs-stream --target-shard-count 2 --endpoint-url http://localhost:4566
```

### For Lower Resource Usage

```yaml
# Reduce poll frequency
POLL_INTERVAL: 10           # From 5s to 10s

# Smaller batches
BATCH_SIZE: 50              # From 100 to 50
```

## 20. Troubleshooting Common Issues

### Issue: "Device or resource busy: /tmp/localstack"

**Cause**: Old LocalStack container holding volume

**Solution**:
```bash
docker compose down -v
docker compose up -d
```

### Issue: "Kinesis producer not available"

**Cause**: kinesis_producer.py not copied to container

**Solution**:
```bash
# Rebuild ingestion-interface
docker compose build ingestion-interface
docker compose up -d ingestion-interface
```

### Issue: Consumer shows "Error parsing record"

**Cause**: Base64 encoding mismatch

**Status**: âœ… FIXED in current version

**Verification**:
```bash
docker logs kinesis-consumer | grep "Wrote.*logs"
# Should show successful writes
```

## 21. Documentation

### Detailed Guides
- **[dashboard/README.md](./dashboard/README.md)** - Dashboard API documentation
- **[plan.md](./plan.md)** - Architecture plan vÃ  design decisions
- **[../README.md](../README.md)** - Full pipeline documentation
- **[../00-mock-servers/README.md](../00-mock-servers/README.md)** - Stage 00 documentation

### Quick Reference
- Dashboard: http://localhost:8010
- LocalStack: http://localhost:4566
- Test script: `./test-kinesis.sh`
- Start script: `./start.sh`

## 22. FAQ

**Q: Táº¡i sao dÃ¹ng Consumer service thay vÃ¬ Lambda?**
A: LocalStack Community Edition cÃ³ limitations vá»›i Lambda (Pending state). Consumer service hoáº¡t Ä‘á»™ng tá»‘t vÃ  code Lambda váº«n cÃ³ sáºµn Ä‘á»ƒ deploy AWS tháº­t.

**Q: Data cÃ³ persist khi restart khÃ´ng?**
A: KhÃ´ng vá»›i LocalStack (PERSISTENCE=0). Äá»ƒ persist, set PERSISTENCE=1 nhÆ°ng cÃ³ thá»ƒ gáº·p volume conflicts.

**Q: CÃ³ thá»ƒ scale Kinesis consumer khÃ´ng?**
A: CÃ³, deploy multiple consumers vá»›i shard assignment khÃ¡c nhau. Hoáº·c migrate lÃªn Lambda vá»›i auto-scaling.

**Q: Partition structure cÃ³ thá»ƒ thay Ä‘á»•i khÃ´ng?**
A: CÃ³, sá»­a `generate_s3_key()` function trong `kinesis-consumer/consumer.py`.

**Q: Dashboard cÃ³ real-time streaming khÃ´ng?**
A: Hiá»‡n táº¡i auto-refresh má»—i 10s. WebSocket real-time streaming lÃ  feature future.

## 23. Roadmap

### Completed âœ…
- [x] LocalStack setup vá»›i Kinesis + S3
- [x] Kinesis consumer service
- [x] S3 partitioned storage
- [x] Integration vá»›i Stage 00
- [x] Visual dashboard vá»›i monitoring
- [x] REST API endpoints

### In Progress ğŸ”„
- [ ] Terraform IaC structure (BÆ°á»›c 2)
- [ ] Lambda function for AWS deployment
- [ ] Consumer metrics integration in dashboard

### Planned ğŸ“‹
- [ ] WebSocket real-time log streaming
- [ ] Advanced filtering vÃ  search
- [ ] Performance charts
- [ ] Alert notifications
- [ ] Download logs functionality
- [ ] Terraform modules (s3, kinesis, lambda, iam)
- [ ] CI/CD pipeline
- [ ] Multi-environment support

## 24. Support

**Issues?** Check:
1. Container status: `docker compose ps`
2. Container logs: `docker logs <container-name>`
3. Dashboard: http://localhost:8010
4. Test script: `./test-kinesis.sh`

**Questions?** See:
- [Full Pipeline README](../README.md)
- [Stage 00 README](../00-mock-servers/README.md)
- [Architecture docs](../../challenge-documents/architecture.md)

---

**Stage 01 Status**: âœ… Operational (BÆ°á»›c 1 Complete - 100%)

**Next**: Stage 01 BÆ°á»›c 2 (Terraform IaC) hoáº·c Stage 02 (ETL with AWS Glue)
